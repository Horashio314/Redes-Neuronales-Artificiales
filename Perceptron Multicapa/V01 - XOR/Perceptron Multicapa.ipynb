{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos la función Sigmoid y su derivada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Metodo encargado de retorna la resultado \n",
    "    de la funcion Sigmoid evaluada en x.\n",
    "    \n",
    "    Parametros:\n",
    "        n: int\n",
    "            Valor en la que se evaluara la función.\n",
    "\n",
    "    Retorna:\n",
    "        int: Funcion Sigmoid evaluada en x.\n",
    "    \"\"\"\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    \"\"\"\n",
    "    Metodo encargado de retorna la resultado de la \n",
    "    derivada de la funcion Sigmoid evaluada en x.\n",
    "    \n",
    "    Parametros:\n",
    "        n: int\n",
    "            Valor en la que se evaluara la función.\n",
    "\n",
    "    Retorna:\n",
    "        int: Derivada de la funcion \n",
    "            Sigmoid evaluada en x.\n",
    "    \"\"\"\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos la clase Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multicapa:\n",
    "    \"\"\"\n",
    "    Perceptron Multicapa\n",
    "    Codificación de un perceptron multicapa \n",
    "    capaz de aprender la compuerta XOR.\n",
    "    \"\"\"\n",
    "    def __init__(self, entrada):\n",
    "        \"\"\" \n",
    "        Metodo constructor del preceptron, \n",
    "        inicialza los valores por defecto.\n",
    "\n",
    "        Parametros:\n",
    "            entrada: array-1d\n",
    "                Arreglo con valores iniciales.\n",
    "        \"\"\"\n",
    "        self.entrada = entrada              # Vector de entrada.\n",
    "        self.l = len(self.entrada)          # Par de datos iniciales (Capa oculta).\n",
    "        self.li = len(self.entrada[0])      # N° de cada par (Capa inicial).\n",
    "\n",
    "        # Vector de pesos de la capa de entrada.\n",
    "        self.wi = np.random.random((self.li, self.l))       \n",
    "        \n",
    "        # Vector de pesos de la capa oculta.\n",
    "        self.wh = np.random.random((self.l, 1))             \n",
    "\n",
    "    def respuesta(self, entrada):\n",
    "        \"\"\" \n",
    "        Salida del perceptron multicapa, aplica el producto \n",
    "        punto entre w (pesos) y entrada (data).\n",
    "        \n",
    "        Parametros:\n",
    "            entrada: array-1d\n",
    "                Arreglo con valores aleatorios iniciales.\n",
    "\n",
    "        Retorna:\n",
    "            array-1d: Respuesta del perceptron de los datos de entrada \n",
    "                    despues de la capa de entrada y la capa oculta.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Producto punto entre los datos de entrada y los pesos de la capa de entrada.\n",
    "        s1 = sigmoid(np.dot(entrada, self.wi))      \n",
    "        \n",
    "        # Producto punto entre la salida anterior y la capa oculta.\n",
    "        s2 = sigmoid(np.dot(s1, self.wh))           \n",
    "        \n",
    "        # Se retorna la salida de los datos despues de la capa oculta.\n",
    "        return s2                                   \n",
    "\n",
    "    def entrenamiento(self, entrada, salidas, iteraciones = 100000, error = 0.005):\n",
    "        \"\"\"\n",
    "        Metodo encargado de entrenar el perceptron multicapa.\n",
    "\n",
    "        Parametros:\n",
    "            entrada: Array, forma [[x1, y1], [x2, y2], ... , [xn, yn]]\n",
    "                Vector con los datos de entrada, cada elemento \n",
    "                es un par de datos de entrada.\n",
    "\n",
    "            salidas: Array, forma [[s1], [s2], ... , [sn]]\n",
    "                Vector con los datos de salida, cada elemento es \n",
    "                la salida correspondiente del vector de entrada.\n",
    "\n",
    "            iteraciones: int, numero de iteraciones maxima que tendra \n",
    "                el perceptron multicapa para entrenar.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Determina si el perceptron aprendio segun el criterio.\n",
    "        aprendio = False            \n",
    "        \n",
    "        # Numero de iteracion que le tomo al perceptron aprender.\n",
    "        iter = 0                    \n",
    "        \n",
    "        # Valor promedio del error en la iteracion actual.\n",
    "        promedio = 0                \n",
    "\n",
    "        while not aprendio:         # Mientras no aprenda.\n",
    "            # Se asigna a la variable local los valores de entrada.\n",
    "            l0 = entrada                            \n",
    "\n",
    "            # Se realiza un producto punto entre los datos de entrada y el \n",
    "            # vector peso de la capa de entrada.\n",
    "            l1 = sigmoid(np.dot(l0, self.wi))       \n",
    "\n",
    "            # Se toma la salida anterior y se realiza un producto punto con \n",
    "            # el vector peso de la capa oculta.\n",
    "            l2 = sigmoid(np.dot(l1, self.wh))       \n",
    "\n",
    "            # Se toma el vector de error de la salida del perceptron con el real.\n",
    "            l2_err = salidas - l2                               \n",
    "\n",
    "            # Se haya el delta error de la capa oculta multiplicando el error \n",
    "            # de la capa oculta con la derivada de la funcion sigmoid.\n",
    "            l2_delta = np.multiply(l2_err, sigmoid_der(l2))     \n",
    "            \n",
    "            # Se toma el vector error de la capa de entrada de un producto \n",
    "            # punto entre el vector delta error de la capa oculta y el\n",
    "            # vector peso de la capa de salida.\n",
    "            l1_err = np.dot(l2_delta, self.wh.T)\n",
    "\n",
    "            # Se haya el delta error de la capa de entrada multiplicando el \n",
    "            # error de la capa de la capa de entrada con la derivada de la \n",
    "            # funcion sigmoid.\n",
    "            l1_delta = np.multiply(l1_err, sigmoid_der(l1))\n",
    "\n",
    "            # Se actualizan los pesos de respectivas capas con los datos \n",
    "            # correspodientes y vectores delta de errores.\n",
    "            self.wh += np.dot(l1.T, l2_delta)\n",
    "            self.wi += np.dot(l0.T, l1_delta)\n",
    "\n",
    "            # Se contabiliza la iteracion para el criterio de aprendizaje.\n",
    "            iter += 1\n",
    "            promedio = np.mean(abs(l2_err))\n",
    "\n",
    "            # Criterio de salida: \n",
    "            # Si el error promedio es menor o igual 0.005, o \n",
    "            # la iteracion de aprendizaje sobrepasa el 100000\n",
    "            if error >= promedio or iter >= iteraciones:        \n",
    "                # Se imprime las iteraciones necesarias para aprender.\n",
    "                print(\"Iteraciones {}\".format(iter))            \n",
    "\n",
    "                # Se imprime el error promedio de la ultima iteracion.\n",
    "                print(\"Error promedio {}\".format(promedio))     \n",
    "\n",
    "                # Salida del perceptron.\n",
    "                aprendio = True      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalmente definimos el main para probar el Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70599688]\n",
      " [0.74714183]\n",
      " [0.73136076]\n",
      " [0.76787252]]\n",
      "\n",
      "Iteraciones 82622\n",
      "Error promedio 0.004999978678808071\n",
      "[[0.00457964]\n",
      " [0.99488506]\n",
      " [0.99487496]\n",
      " [0.00518018]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    entrada = np.array([[0,0], [0,1], [1,0], [1,1]])    # Vector de entrada.\n",
    "    salidas = np.array([[0], [1], [1], [0]])            # Vector de salida.\n",
    "    \n",
    "    n = Multicapa(entrada)                  # Se instancia del perceptron.\n",
    "    print(n.respuesta(entrada))             # Salida sin entrenar.\n",
    "    print(\"\")\n",
    "    n.entrenamiento(entrada, salidas)       # Se entrena el perceptron multicapa.\n",
    "    print(n.respuesta(entrada))             # Salida despues de entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar como la primera salida es el resultado del perceptron sin entrenar, una vez entrado, se imprime el numero de iteraciones que le tomo aprender con un error promedio no mayor al 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguido se muestra la salida del perceptron con los mismos datos de entrada de la primera salida, siendo estas muy proximos a los reales dado el criterio de aprendizaje:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0.004 =~ 0\n",
    "    0.994 =~ 1\n",
    "    0.994 =~ 1\n",
    "    0.005 =~ 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
