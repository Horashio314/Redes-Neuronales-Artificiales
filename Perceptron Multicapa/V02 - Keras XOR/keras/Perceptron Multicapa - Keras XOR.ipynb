{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos la clase Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keras:\n",
    "    \"\"\"\n",
    "    Perceptron Multicapa\n",
    "    Codificación de un perceptron multicapa capaz de aprender \n",
    "    la compuerta XOR mediante la libreria Keras y TensorFlow.\n",
    "    \"\"\"\n",
    "    def __init__(self, seed = 7):\n",
    "        \"\"\" \n",
    "        Metodo constructor de la red, \n",
    "        inicialza los valores por defecto.\n",
    "\n",
    "        Parametros:\n",
    "            seed: int\n",
    "                Fija las semillas aleatorias para la reproducibilidad,\n",
    "                con el objetivo de tener la misma salida siempre.\n",
    "        \"\"\"\n",
    "        numpy.random.seed(seed)\n",
    "\n",
    "        # Inicializa el modelo para la red.\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # Datos de entrada y salida\n",
    "        self.entrada = [] \n",
    "\n",
    "    def cargarData(self, FICHERO):\n",
    "        \"\"\"\n",
    "        Metodo destinado a cargar los datos en la red del set de datos.\n",
    "        \"\"\"\n",
    "        # Carga el set de datos de la compuerta XOR de FICHERO.\n",
    "        dataset = numpy.loadtxt(FICHERO, delimiter=',')\n",
    "\n",
    "        # Separa las entrada y salidas.\n",
    "        self.entrada = dataset[:, 0:2]\n",
    "        self.salidas = dataset[:, 2]\n",
    "\n",
    "    def cargarModelo(self):\n",
    "        \"\"\"\n",
    "        Metodo destinado a cargar el modelo que se desea en la red:\n",
    "        Utilizando la clase Dense, se puede anidar varias capas para el \n",
    "        perceptron, el primer parametro determina las neuronas que se \n",
    "        utilizaran, el segundo la cantidad de datos de entrada, y el \n",
    "        tercero la funcion de activacion. Finalmente, un perceptron de tres \n",
    "        capas con numero de neuronales variables por capa y distintas funciones \n",
    "        de activacion.\n",
    "        \"\"\"\n",
    "        # Capa 1.\n",
    "        # 12 neuronas, 2 datos de entrada, funcion de activacion: rectificador.\n",
    "        self.model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "        \n",
    "        # Capa 2.\n",
    "        # 2 neuronas, funcion de activacion: rectificador\n",
    "        self.model.add(Dense(2, activation='relu'))\n",
    "\n",
    "        # Capa 3.\n",
    "        # 1 neurona, funcion de activacion: Sigmoid\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    def compilarModelo(self):\n",
    "        \"\"\"Metodo encargado de compilar el modelo previamente diseñado\"\"\"\n",
    "        \n",
    "        # Debemos especificar la función de pérdida para un conjunto de pesos,\n",
    "        # el optimizador para buscar a través de diferentes pesos para la red \n",
    "        # y cualquier métrica opcional que nos gustaría recopilar y reportar \n",
    "        # durante el entrenamiento.\n",
    "\n",
    "        # En este caso, utilizaremos la pérdida logarítmica, \n",
    "        # que para un problema de clasificación binaria se define en Keras \n",
    "        # como “binary_crossentropy”. Algoritmo de descenso de gradiente \n",
    "        # “adam” por su alta eficiencia en estos problemas, y \"accuracy\" \n",
    "        # como la métrica, totalmente a criterio del diseñador.\n",
    "        self.model.compile(loss='binary_crossentropy', \n",
    "                           optimizer='adam', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "    def entrenamiento(self):\n",
    "        \"\"\"Metodo encargado de entrenar la red.\"\"\"\n",
    "\n",
    "        # El siguiente metodo utiliza los datos de entrada y salida previamnete\n",
    "        # cargados para entrenar la red, \"epochs\" representa el numero de \n",
    "        # iteraciones que tendra para entrenar, \"batch_size\" representa el \n",
    "        # numero de iteraciones antes de actualizar los pesos de las capas, y \n",
    "        # \"verbose\" representa las salidad por pantalla de cada iteracion del \n",
    "        # entramiento (Nota: en caso de querer estudiar las salidad por \n",
    "        # iteracion eliminar el ultimo parametro).\n",
    "        self.model.fit(self.entrada, \n",
    "                       self.salidas, \n",
    "                       epochs=1000, \n",
    "                       batch_size=10, \n",
    "                       verbose=0)\n",
    "        \n",
    "    def evaluador(self):\n",
    "        \"\"\"Metodo encargado de evaluar los parametro de la red.\"\"\"\n",
    "\n",
    "        # Evalua las metricas de red con los datos de entrada y salida.\n",
    "        scores = self.model.evaluate(self.entrada, self.salidas)\n",
    "\n",
    "        # Imprime el porcentaje de acierto que tiene la red.\n",
    "        print(\"%s: %.2f%%\" % (self.model.metrics_names[1], scores[1] * 100))\n",
    "        \n",
    "    def respuesta(self):\n",
    "        \"\"\"\n",
    "        Salida de la red, aplica metodo de prediccion luego del entrenamiento.\n",
    "        \"\"\"\n",
    "        # Calcula el resultado con datos de entrada luego del entrenamiento.\n",
    "        predicciones = self.model.predict(self.entrada)\n",
    "\n",
    "        # Redondeamos las predicciones\n",
    "        redondeo = [round(x[0]) for x in predicciones]\n",
    "        print(\"Salida de la red:\", redondeo)\n",
    "\n",
    "        # Descomentar la siguiente linea en caso de querer observar los \n",
    "        # datos reales de prediccion, sin el redondeo.\n",
    "        # print(predicciones) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hara un enfasis en el metodo del entrenamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notese los parametros \"epochs\" y \"batch_size\", los mismos son muy importantes en esta ocasion, ya que sus valores depende plenamente del diseñador de la red, mediante ensayo y error, estos valores son los que ayudan finalmente a que la red termine aprendiendo correcta o incorrectamente con los datos de entradas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main principal para probar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de la red: [0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "4/4 [==============================] - 0s 15ms/step\n",
      "acc: 100.00%\n",
      "Salida de la red: [0.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Eliminacion de mensajes de advertencia de TensorFlow y Keras.\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    # Ruta del fichero con la data de entrada.\n",
    "    FICHERO = 'data/data-xor.csv'\n",
    "\n",
    "    # Se inicializa la red.\n",
    "    k = Keras()\n",
    "\n",
    "    # Se cargan los datos de entrada.\n",
    "    k.cargarData(FICHERO)\n",
    "\n",
    "    # Se carga el modelo del perceptron y se compila.\n",
    "    k.cargarModelo()\n",
    "    k.compilarModelo()\n",
    "\n",
    "    # Se obtiene la respuesta de la red sin entrenar\n",
    "    k.respuesta()\n",
    "    print(\"\")\n",
    "\n",
    "    # Se entrena la red para la compuerta XOR.\n",
    "    k.entrenamiento()\n",
    "\n",
    "    # Se evalua el porcetanje de acierto de la red.\n",
    "    k.evaluador()\n",
    "\n",
    "    # Se obtiene la respuesta de la red luego de entrenarla.\n",
    "    k.respuesta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera salida de la red, es de cuando aún, la misma, no se ha entrenado, por lo que resulta como solo ceros, mientras que después de entrenarla, podemos observar en la respuesta de evaluarla como el \"acc\" o la métrica \"accuracy\" que difinimos anteriormente en el modelo, nos muestra un \"100.00%\", esto representa el porcentaje de acierto que tiene la red. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, la ultima salida de la red representa la prediccion de la misma, una vez entrenada con los datos de entrada, resultando la compuerta XOR:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [x1, x2] -----> [s]\n",
    "      [0, 0] -----> [0]\n",
    "      [0, 1] -----> [1]\n",
    "      [1, 0] -----> [1]\n",
    "      [1, 1] -----> [0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
