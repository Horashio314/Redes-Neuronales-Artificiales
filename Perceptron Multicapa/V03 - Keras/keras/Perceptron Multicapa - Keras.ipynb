{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos la clase Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keras:\n",
    "    \"\"\"\n",
    "    Perceptron mediante la libreria Keras y TensorFlow.\n",
    "    \"\"\"\n",
    "    def __init__(self, seed = 7):\n",
    "        \"\"\" \n",
    "        Metodo constructor de la red, \n",
    "        inicialza los valores por defecto.\n",
    "\n",
    "        Parametros:\n",
    "            seed: int\n",
    "                Fija las semillas aleatorias para la reproducibilidad,\n",
    "                con el objetivo de tener la misma salida siempre.\n",
    "        \"\"\"\n",
    "        numpy.random.seed(seed)\n",
    "\n",
    "        # Inicializa el modelo para la red.\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # Datos de entrada y salida\n",
    "        self.entrada = [] \n",
    "        self.salidas = []\n",
    "\n",
    "    def cargarData(self, FICHERO):\n",
    "        \"\"\"\n",
    "        Metodo destinado a cargar los datos en la red del set de datos.\n",
    "        \"\"\"\n",
    "        # Carga el set de datos de la compuerta XOR de FICHERO.\n",
    "        dataset = numpy.loadtxt(FICHERO, delimiter=',')\n",
    "\n",
    "        # Separa las entrada y salidas.\n",
    "        self.entrada = dataset[:, 0:8]\n",
    "        self.salidas = dataset[:, 8]\n",
    "\n",
    "    def cargarModelo(self):\n",
    "        \"\"\"\n",
    "        Metodo destinado a cargar el modelo que se desea en la red:\n",
    "        Utilizando la clase Dense, se puede anidar varias capas para el \n",
    "        perceptron, el primer parametro determina las neuronas que se \n",
    "        utilizaran, el segundo la cantidad de datos de entrada, y el \n",
    "        tercero la funcion de activacion. Finalmente, un perceptron de tres \n",
    "        capas con numero de neuronales variables por capa y distintas funciones \n",
    "        de activacion.\n",
    "        \"\"\"\n",
    "        # Capa 1.\n",
    "        # 12 neuronas, 8 datos de entrada, funcion de activacion: rectificador.\n",
    "        self.model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "        \n",
    "        # Capa 2.\n",
    "        # 8 neuronas, funcion de activacion: rectificador\n",
    "        self.model.add(Dense(8, activation='relu'))\n",
    "\n",
    "        # Capa 3.\n",
    "        # 1 neurona, funcion de activacion: Sigmoid\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    def compilarModelo(self):\n",
    "        \"\"\"Metodo encargado de compilar el modelo previamente diseñado\"\"\"\n",
    "        \n",
    "        # Debemos especificar la función de pérdida para un conjunto de pesos,\n",
    "        # el optimizador para buscar a través de diferentes pesos para la red \n",
    "        # y cualquier métrica opcional que nos gustaría recopilar y reportar \n",
    "        # durante el entrenamiento.\n",
    "\n",
    "        # En este caso, utilizaremos la pérdida logarítmica, \n",
    "        # que para un problema de clasificación binaria se define en Keras \n",
    "        # como “binary_crossentropy”. Algoritmo de descenso de gradiente \n",
    "        # “adam” por su alta eficiencia en estos problemas, y \"accuracy\" \n",
    "        # como la métrica, totalmente a criterio del diseñador.\n",
    "        self.model.compile(loss='binary_crossentropy', \n",
    "                           optimizer='adam', \n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    def entrenamiento(self):\n",
    "        \"\"\"Metodo encargado de entrenar la red.\"\"\"\n",
    "\n",
    "        # El siguiente metodo utiliza los datos de entrada y salida previamnete\n",
    "        # cargados para entrenar la red, \"epochs\" representa el numero de \n",
    "        # iteraciones que tendra para entrenar, \"batch_size\" representa el \n",
    "        # numero de iteraciones antes de actualizar los pesos de las capas, y \n",
    "        # \"verbose\" representa las salidad por pantalla de cada iteracion del \n",
    "        # entramiento (Nota: en caso de querer estudiar las salidad por \n",
    "        # iteracion eliminar el ultimo parametro).\n",
    "        self.model.fit(self.entrada, \n",
    "                       self.salidas, \n",
    "                       epochs=150, \n",
    "                       batch_size=10, \n",
    "                       verbose=0)\n",
    "\n",
    "    def evaluador(self):\n",
    "        \"\"\"Metodo encargado de evaluar los parametro de la red.\"\"\"\n",
    "\n",
    "        # Evalua las metricas de red con los datos de entrada y salida.\n",
    "        scores = self.model.evaluate(self.entrada, self.salidas)\n",
    "\n",
    "        # Imprime el porcentaje de acierto que tiene la red.\n",
    "        print(\"%s: %.2f%%\" % (self.model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "    def respuesta(self):\n",
    "        \"\"\"\n",
    "        Salida de la red, aplica metodo de prediccion luego del entrenamiento.\n",
    "        \"\"\"\n",
    "        # Calcula el resultado con datos de entrada luego del entrenamiento.\n",
    "        predicciones = self.model.predict(self.entrada)\n",
    "\n",
    "        # Redondeamos las predicciones\n",
    "        redondeo = [round(x[0]) for x in predicciones]\n",
    "        print(\"Salida de la red:\", redondeo)\n",
    "\n",
    "        # Descomentar la siguiente linea en caso de querer observar los \n",
    "        # datos reales de prediccion, sin el redondeo.\n",
    "        # print(predicciones) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hara un enfasis en el metodo del entrenamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notese los parametros \"epochs\" y \"batch_size\", los mismos son muy importantes en esta ocasion, ya que sus valores depende plenamente del diseñador de la red, mediante ensayo y error, estos valores son los que ayudan finalmente a que la red termine aprendiendo correcta o incorrectamente con los datos de entradas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main principal para probar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de acierto despues de entrenar:\n",
      "768/768 [==============================] - 0s 129us/step\n",
      "acc: 78.52%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Eliminacion de mensajes de advertencia de TensorFlow y Keras.\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    # Ruta del fichero con la data de entrada.\n",
    "    FICHERO = 'data/pima-indians-diabetes.csv'\n",
    "\n",
    "    # Se inicializa la red.\n",
    "    k = Keras()\n",
    "\n",
    "    # Se cargan los datos de entrada.\n",
    "    k.cargarData(FICHERO)\n",
    "\n",
    "    # Se carga el modelo del perceptron y se compila.\n",
    "    k.cargarModelo()\n",
    "    k.compilarModelo()\n",
    "\n",
    "    # Se obtiene la respuesta de la red sin entrenar, descomentar \n",
    "    # en caso de querer ver toda la salida.\n",
    "    #k.respuesta()\n",
    "    #print(\"\")\n",
    "\n",
    "    # Se entrena la red para los datos de personas diabeticas.\n",
    "    k.entrenamiento()\n",
    "\n",
    "    # Se evalua el porcetanje de acierto de la red.\n",
    "    print(\"Porcentaje de acierto despues de entrenar:\")\n",
    "    k.evaluador()\n",
    "\n",
    "    # Se obtiene la respuesta de la red luego de entrenarla, descomentar \n",
    "    # en caso de querer ver toda la salida desdpues de entrenarla.\n",
    "    #k.respuesta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar en la respuesta de evaluarla como el \"acc\" o la métrica \"accuracy\" que difinimos anteriormente en el modelo, nos muestra un \"78.52%\", esto representa el porcentaje de acierto que tiene la red. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver los datos de salida antes y depues del entrenar, descomentar las lineas 21, 22 y 33. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
